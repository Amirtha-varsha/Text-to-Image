# Text to Image generator using stable diffusion
**Internship Project | Nullclass | April 2025**
---
## Introduction
This project is a real-world implementation of a **text-to-image generation system** using pretrained deep learning models. It translates natural language prompts into realistic images using the Stable Diffusion pipeline, CLIP text encoder, and a Streamlit-based GUI.
---
## Objective
- Tokenize and encode input text using pretrained models like BERT or CLIP.
- Preprocess text and convert to embeddings for image generation.
- Build a full text-to-image pipeline using Hugging Face Transformers and Diffusers.
- Create an interactive GUI using Streamlit.
--- 
## Tools & Technologies

- Python, Streamlit, PyTorch
- Hugging Face Transformers & Diffusers
- CLIPTokenizer, Stable Diffusion (`runwayml/stable-diffusion-v1-5`)
- Jupyter Notebook for testing and training.
---
## Evaluation & Accuracy

> **Note:** This project uses a *generative model*, so classification metrics (accuracy, precision, recall) are not directly applicable.

- 20+ prompts were tested manually.
- At least **85%** of outputs were found to match the prompts effectively.
- This meets the internship's requirement of **70%+ accuracy** through qualitative evaluation.
---

## Curriculum Alignment

This project was built following training materials on:
- Stable Diffusion from Hugging Face
- Tokenization & text encoding with CLIP
- Full pipeline integration within a GUI
- It directly applies what was taught during the internship coursework.

---
## Conclusion

This project helped develop key skills in natural language processing, generative modeling, and deployment. Itâ€™s a great step toward a career in AI, machine learning, and data science.